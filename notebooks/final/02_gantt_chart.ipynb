{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad798a4-6d70-4f03-ac32-be9027965aef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'initial_pert'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# from crash_cost_analysis import run_crash_analysis\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minitial_pert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_pert_analysis \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcompletion_probability\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_completion_probability_ui\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplot_aoa_diagram\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_aoa_network\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'initial_pert'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# from crash_cost_analysis import run_crash_analysis\n",
    "from initial_pert import run_pert_analysis \n",
    "from completion_probability import show_completion_probability_ui\n",
    "from plot_aoa_diagram import plot_aoa_network\n",
    "# # from plot_aoa import plot_aoa_network\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "# # sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"scripts\")))\n",
    "# # import sys\n",
    "# # import os\n",
    "# sys.path.append(os.path.dirname(__file__))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st.title(\"ðŸ“Š PERT Scheduler + Crash Cost Analyzer\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"ðŸ“¥ Upload Cleaned Excel\", type=[\"xlsx\"])\n",
    "\n",
    "if uploaded_file:\n",
    "    df = pd.read_excel(uploaded_file)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Rename for consistency\n",
    "    df = df.rename(columns={\n",
    "        \"Most Likely\": \"MostLikely\",\n",
    "        \"Optimistic Time\": \"Optimistic\",\n",
    "        \"Pessimistic Time\": \"Pessimistic\",\n",
    "        \"Predecessors\": \"Dependencies\",\n",
    "        \"Activity\": \"Activity_id\",\n",
    "        \"Activity Name\": \"Activity N\",\n",
    "\n",
    "    })\n",
    "\n",
    "    st.subheader(\"ðŸ§¾ Raw Data\")\n",
    "    st.dataframe(df)\n",
    "\n",
    "    if st.button(\"ðŸš€ Run PERT Analysis\"):\n",
    "        result_df, critical_path, G = run_pert_analysis(df)      # debug 1\n",
    "        st.success(\"PERT Analysis Complete âœ…\")\n",
    "        st.write(\"ðŸ”´ Critical Path:\", \" â†’ \".join(critical_path))   # maybe\n",
    "        st.dataframe(result_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d95b87d9-d832-41fd-8327-28b476536586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "def run_pert_analysis(df):\n",
    "    \n",
    "\n",
    "    # Calculate Expected Time using PERT formula\n",
    "    df[\"ExpectedTime\"] = (df[\"Optimistic\"] + 4 * df[\"MostLikely\"] + df[\"Pessimistic\"]) / 6\n",
    "    df[\"Variance\"] = ((df[\"Pessimistic\"] - df[\"Optimistic\"]) / 6) ** 2\n",
    "\n",
    "    # Initialize graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes with duration\n",
    "    for _, row in df.iterrows():\n",
    "        act_id = row[\"Activity_id\"]\n",
    "        label = f\"{act_id} - {row['Activity N']}\"\n",
    "        G.add_node(label, duration=row[\"ExpectedTime\"])\n",
    "\n",
    "    # Add edges based on dependencies\n",
    "    for _, row in df.iterrows():\n",
    "        current = f\"{row['Activity_id']} - {row['Activity N']}\"\n",
    "        if pd.notna(row[\"Dependencies\"]):\n",
    "            deps = [d.strip() for d in str(row[\"Dependencies\"]).split(',')]\n",
    "            for dep in deps:\n",
    "                dep_name = df[df[\"Activity_id\"] == dep][\"Activity N\"].values\n",
    "                if len(dep_name) == 0:\n",
    "                    continue\n",
    "                dep_full = f\"{dep} - {dep_name[0]}\"\n",
    "                G.add_edge(dep_full, current)\n",
    "\n",
    "    # Forward pass (Early Start and Finish)\n",
    "    ES, EF = {}, {}\n",
    "    for node in nx.topological_sort(G):\n",
    "        preds = list(G.predecessors(node))\n",
    "        ES[node] = max([EF[p] for p in preds], default=0)\n",
    "        EF[node] = ES[node] + G.nodes[node]['duration']\n",
    "        G.nodes[node]['ES'] = ES[node]\n",
    "        G.nodes[node]['EF'] = EF[node]\n",
    "\n",
    "    # Backward pass (Late Start and Finish)\n",
    "    LS, LF = {}, {}\n",
    "    max_EF = max(EF.values())\n",
    "    for node in reversed(list(nx.topological_sort(G))):\n",
    "        succs = list(G.successors(node))\n",
    "        LF[node] = min([LS[s] for s in succs], default=max_EF)\n",
    "        LS[node] = LF[node] - G.nodes[node]['duration']\n",
    "        G.nodes[node]['LS'] = LS[node]\n",
    "        G.nodes[node]['LF'] = LF[node]\n",
    "        G.nodes[node]['Slack'] = LS[node] - ES[node]\n",
    "\n",
    "    # Critical Path\n",
    "    critical_path = [node for node in G.nodes if G.nodes[node]['Slack'] == 0]\n",
    "\n",
    "    # Convert to result dataframe\n",
    "    result_data = []\n",
    "    for node in G.nodes:\n",
    "        result_data.append({\n",
    "            \"Activity N\": node,\n",
    "            \"Duration\": G.nodes[node]['duration'],\n",
    "            \"ES\": G.nodes[node]['ES'],\n",
    "            \"EF\": G.nodes[node]['EF'],\n",
    "            \"LS\": G.nodes[node]['LS'],\n",
    "            \"LF\": G.nodes[node]['LF'],\n",
    "            \"Slack\": G.nodes[node]['Slack'],\n",
    "            \"IsCritical\": node in critical_path\n",
    "        })\n",
    "    result_df = pd.DataFrame(result_data)\n",
    "\n",
    "    return result_df, critical_path, G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1961cc6d-e786-4917-8a16-e1d024a0d8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef6c870-5e28-41a8-9b3c-8cddc2da8d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368aede7-affe-4715-9814-b83194a4f375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
